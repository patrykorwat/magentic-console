{
  "models": [
    {
      "id": "qwen2.5:7b",
      "name": "Qwen 2.5 (7B)",
      "description": "Najlepszy balans jakości i szybkości. Doskonały do większości zadań.",
      "size": "7B parameters",
      "capabilities": ["reasoning", "coding", "analysis", "mcp_tools"],
      "recommended": true
    },
    {
      "id": "llama3.2:3b",
      "name": "Llama 3.2 (3B)",
      "description": "Bardzo szybki, lekki model. Dla prostych pytań i szybkich odpowiedzi.",
      "size": "3B parameters",
      "capabilities": ["simple_qa", "basic_analysis"]
    },
    {
      "id": "llama3.2",
      "name": "Llama 3.2 (1B)",
      "description": "Najlżejszy model. Ultra-szybki dla trywialnych zadań.",
      "size": "1B parameters",
      "capabilities": ["simple_qa"]
    },
    {
      "id": "mistral:7b",
      "name": "Mistral (7B)",
      "description": "Silny w rozumowaniu logicznym i analizie. Dobry dla bardziej złożonych zadań.",
      "size": "7B parameters",
      "capabilities": ["reasoning", "analysis", "mcp_tools"]
    },
    {
      "id": "phi3:medium",
      "name": "Phi-3 Medium",
      "description": "Kompaktowy ale potężny. Dobry w matematyce i logice.",
      "size": "14B parameters",
      "capabilities": ["reasoning", "math", "coding", "mcp_tools"]
    },
    {
      "id": "deepseek-coder-v2:16b",
      "name": "DeepSeek Coder (16B)",
      "description": "Specjalizowany w kodowaniu. Najlepszy dla zadań programistycznych.",
      "size": "16B parameters",
      "capabilities": ["coding", "debugging", "analysis"]
    },
    {
      "id": "qwen2.5-coder:7b",
      "name": "Qwen 2.5 Coder (7B)",
      "description": "Dedykowany do kodu. Świetny balans między kodowaniem a szybkością.",
      "size": "7B parameters",
      "capabilities": ["coding", "debugging", "mcp_tools"]
    }
  ],
  "defaultModel": "qwen2.5:7b",
  "notes": [
    "Modele muszą być pobrane lokalnie: ollama pull <model_name>",
    "Większe modele (>7B) wymagają więcej RAM",
    "Wszystkie modele z 'mcp_tools' mogą używać narzędzi MCP"
  ]
}
